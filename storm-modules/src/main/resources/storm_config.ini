# TEST configuration file for the REVEAL Social Media Client Framework Storm Local cluster
#
# Please read the instructions below on how to configure the example Storm
#
# Vadim 10.02.2014

# Description( [storm-rabbitmq-config] ): Storm RabbitMQ configuration (these configuration parameters should be consistent with RabitMQ broker installed on your machine,
# as well as with another entity that will be publishing messages to a RabbitMQ for the Storm processing e.g. some entity will be publishing messages to RabbitMQ queue, Storm spout need to
# know that queue in order to start received message processing etc).
#  - rmqhost: RabbitMQ host
#  - rmqport: RabbitMQ port
#  - rmqusername: RabbitMQ Username
#  - rmqpassword: RabbitMQ Password
#  - rmqheartbeat: RabbitMQ heartbeat (ensure that the application layer promptly finds out about disrupted connections (and also completely unresponsive peers)
#  - rmqqueuename: RabbitMQ queue name
#  - rmqexchange: RabbitMQ exchange
#  - rmqexchangetype: RabbitMQ exchange type
#  - rmqrouting: RabbitMQ routing
#  - amqpschemeencoding: AMQP Storm Spout message encoding
[storm-rabbitmq-config]
rmqhost=localhost
rmqport=5672
rmqusername=guest
rmqpassword=guest
rmqheartbeat=10
rmqqueuename=certh
rmqexchange=certh-exchange
rmqexchangetype=topic
rmqrouting=test-routing
amqpschemeencoding=utf-8


# Description( [storm-topology-configuration] ): Storm topology configuration parameters
#  - topology_debug: Boolean flag that will enable/disable Topology debug information (NOTE: Storm topology is very verbose itself, therefore the Topology debug is set to false)
[storm-topology-configuration]
topology_debug=false


# Description( [storm-spout-configuration] ): Storm AMQP Spout configuration parameters
#  - spout_debug: Boolean flag that will enable/disable Spout debug information (NOTE: as was mentioned earlier, Storm topology is very verbose itself, therefore the Spout debug is also set to false)
#  - spout_rmqprefetch: RabbitMQ AMQP Spout prefetch n-amount of messages from the Queue. Since the streaming data can fill up the message queue quite quickly, the n-amount of prefetched messages need to
#    be realistic to the amount of published messages (to avoid queue "overfilling")
#  - spout_max_spout_pending: Applies to the above (spout_rmqprefetch) where n-amount of messages need to be prefetched, but in this case from the RabbitMQ queue message consumer point of view. Make sure that the value is the same as RabbitMQ
#    prefetch count (MaxSpoutPending <= Prefetch).
[storm-spout-configuration]
spout_debug=false
spout_rmqprefetch=200
spout_max_spout_pending=200


# Description( [storm-spouts-bolts-ids] ): Storm Spout and Bolt ids configuration parameters. The ids are needed when declaring Spouts and Bolts in the Storm topology.
#  - example_python_storm_topology_id: Id of Python Storm Topology (e.g. a  Storm topology that contains Python and Java bolts)
#  - example_java_storm_topology_id: Id of Java Storm Topology (e.g. a  Storm topology that contains only Java bolts)
#  - example_spout_amqp_spout_id: Id of the main AMQP Spout (main Storm Spout RabbitMQ messages consumer)
#  - example_bolt_java_printer_bolt_id: Id of the Java Printer Bolt (Bolt that simply prints received messages that will be emitted from the Python Logger Bolt)
#  - example_bolt_python_logger_bolt_id: Id of the Python Logger Bolt (Python Bolt that log received messages that will be emitted from the main AMPQ Spout)
#  - example_bolt_java_logger_bolt_id: Id of the Python Logger Bolt (Java Bolt that log received messages that will be emitted from the main AMPQ Spout)
[storm-spouts-bolts-ids]
example_python_storm_topology_id=examplePythonStormTopology
example_java_storm_topology_id=exampleJavaStormTopology
example_spout_amqp_spout_id=exampleSocialMediaAMQPSpout
example_bolt_java_printer_bolt_id=exampleJavaPrinterBolt
example_bolt_python_logger_bolt_id=examplePythonLoggerBolt
example_bolt_java_logger_bolt_id=exampleJavaLoggerBolt
indexing_bolt_id=indexingBolt
certh_topology_id=certhTopology


# Description( [emit-fields-names] ): Name of the Storm Spout/Bolt emitted messages (simply a String) which does not really have any significant meaning on overall Storm Topology (as well as Spout/Bolt) functionality
#  - example_emit_fields_id: Name of the Storm Spout/Bolt emitted messages
[emit-fields-names]
example_emit_fields_id=object


# Description( [multilang-bolt-filename] ): Name of the "multilanguage" (in Storm all Spouts/Bolts that are not implemented in Java a called "multilanguage") Python Logger Bolt. By specifying the name of the
# bolt in the configuration file gives more flexibility on what multilanguage Java Bolt "wrapper" (initially Python Bolt will be started as a sub-process from the Java "wrapper" bolt) can start.
#  - example_multilang_python_bolt_filename: Name of the multilanguage script that Java "wrapper" Bolt will start
[multilang-bolt-filename]
example_multilang_python_bolt_filename=ExampleSocialMediaLogger.py


# Description( [storm-logging] ): main example Storm logging settings
#  - logging_pattern_java: Logging pattern for java log (will result of the message similar to: INFO 2014-03-31 16:27:57 Module_Name main 425: Declared Logger Bolt to the example Storm topology)
#  - logging_pattern_python: Logging pattern for python log (will result of the message similar to: INFO 2014-03-31 16:27:57 ExampleJavaSocialMediaStormTopologyRunner.java main 425: Declared Logger Bolt to the example Storm topology)
#  - logging_level: Logging level (e.g. all, trace, debug, info, warn or error )
#  - logging_dir:  Will be used by spouts and bolts. log filenames will be in format e.g. <logging_dir>\ExampleSocialMediaLogger_pid123456.log
[storm-logging]
logging_pattern_java=\%5p \%d{yyyy-MM-dd HH:mm:ss,sss} \%file \%t \%L\: \%m\%n
logging_pattern_python=\%\(levelname\) \-s \%\(asctime\)s \%\(name\) \-s \%\(funcName\) \-s \%\(lineno\) \-d\: \%\(message\)s
logging_level=debug
#logging_dir=/home/kandreadou/mklab/logs
logging_dir=/var/logs

[visual-indexing]
#visual_learning_files=/home/kandreadou/webservice/learning_files/
visual_learning_files=/usr/learning_files/
visual_service_host=127.0.0.1

